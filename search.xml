<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F08%2F11%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. mermaidgraph TD; A—&gt;B; A—&gt;C; B—&gt;D; C—&gt;D; Quick Start Create a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 第一段]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特征工程-特征归一化]]></title>
    <url>%2F2019%2F08%2F06%2F%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B-%E7%89%B9%E5%BE%81%E5%BD%92%E4%B8%80%E5%8C%96%2F</url>
    <content type="text"><![CDATA[为什么要归一化？在实际应用中，通过梯度下降一类的方法需要进行归一化，比如逻辑回归，线性回归，SVM，神经网络，Adaboost，SVM，LR，Knn，KMeans等。但是决策树，朴素贝叶斯，隐马尔可夫等模型不需要归一化。因为前者是基于数值的决策，对单位敏感度高，如果不进行归一化操作可能会导致x/y中有一个变量的影响力$\uparrow$，可能需要更多轮次的迭代才能得到最终解。后者基于交叉熵的信息增益，基于概率分布模型，而概率本身是归一化的（%），所以不需要归一化。 ![upload successful](\images\pasted-1.png) 逻辑回归一定要归一化么？如果你用了L1L2正则的话需要，因为不用正则时，我们的损失函数只是仅仅在度量预测与真实的差距，加上正则后，我们的损失函数除了要度量上面的差距外，还要度量参数值是否足够小。而参数值的大小程度是与特征的数值范围相关的。 归一化的方法 线性函数归一化（适用于简单数值）：$X=\frac{X-X{min}}{X{max}-X_{min}}$ 0均值归一化：$z=\frac{x-u}{\sigma}$]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
</search>
